{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import time\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For both cpu and gpu integration all the variables and models should use\n",
    "# \"xx.to(device)\"  \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Basic parameters for reproducablity\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if device == \"cuda:0\": \n",
    "    torch.cuda.manual_seed_all(1) # gpu vars\n",
    "\n",
    "# Dataset paths\n",
    "celea_dataset = \"Dataset/HIGH/celea_60000_SFD\"\n",
    "sr_dataset = \"Dataset/HIGH/SRtrainset_2\"\n",
    "vgg_dataset = \"Dataset/HIGH/vggface2/vggcrop_train\"\n",
    "wider_dataset = \"Dataset/LOW/widerface_subset/wider_lnew\"\n",
    "\n",
    "# Model saving paths\n",
    "hightolow_generator = \"Checkpoint/hightolow_g_\"\n",
    "hightolow_discriminator = \"Checkpoint/hightolow_d_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the parameters and dynamic numbers will be setted here\n",
    "hightolow_batch_size = 8 \n",
    "epoch = 200\n",
    "learning_rate = 1e-4\n",
    "loss_a_coeff = 1\n",
    "loss_b_coeff = 0.05\n",
    "adam_beta1 = 0\n",
    "adam_beta2 = 0.9\n",
    "# After each this value of iterations generator will be updated\n",
    "# In original paper it is 5:1\n",
    "generator_update_ratio = 5 \n",
    "# Save the generated images after some interval\n",
    "# to visualize the progress\n",
    "sample_interval = 500\n",
    "\n",
    "high_image_size = 64\n",
    "low_image_size = 16\n",
    "noise_dimension = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model_path,epoch,model,optimizer,loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            },  model_path + epoch)\n",
    "\n",
    "# TODO: Instead of using function to load paste these codes to main loop    \n",
    "def load_checkpoint(model_path,epoch):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    model.eval()\n",
    "    # - or -\n",
    "    model.train()\n",
    "    \n",
    "def batch_to_image(batch):\n",
    "    np_grid = vutils.make_grid(batch).numpy()\n",
    "    plt.imshow(np.transpose(np_grid, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "# Noise distrubition sampled from normal distribution\n",
    "def create_noise():\n",
    "    return torch.randn(hightolow_batch_size,64)\n",
    "\n",
    "def calculate_remaining_training_time(batches_done,batches_left):\n",
    "    print()\n",
    "    #batches_done = epoch * len(dataloader) + i\n",
    "    #batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
    "    #time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for high images\n",
    "def load_image(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "# This dataset use the image datasets where images\n",
    "# are located on the dataset folder and this\n",
    "# Generic dataset should be customized according to the dataset\n",
    "# csv based dataset require different loading function\n",
    "\n",
    "class HighDataset(Dataset):\n",
    "    \"\"\" Initialize the dataset by giving the dataset path and transform that will be applied \"\"\"\n",
    "    def __init__(self,transform = None):\n",
    "        images = []\n",
    "        celea_subjects = [subject for subject in os.listdir(celea_dataset)]\n",
    "        sr_subjects = [subject for subject in os.listdir(sr_dataset)]\n",
    "        vgg_subjects = [subject for subject in os.listdir(vgg_dataset)]\n",
    "        \n",
    "        for subject in celea_subjects:\n",
    "            images.append(os.path.join(celea_dataset,subject))\n",
    "\n",
    "        for subject in sr_subjects:\n",
    "            images.append(os.path.join(sr_dataset,subject))\n",
    "                              \n",
    "        for subject in vgg_subjects:\n",
    "            images.append(os.path.join(vgg_dataset,subject))\n",
    "        \n",
    "                              \n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.count = len(images)\n",
    "        \n",
    "\n",
    "    \"\"\" Image with given index will be loaded by using the image path \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = load_image(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "    \n",
    "\n",
    "class LowDataset(Dataset):\n",
    "    \"\"\" Initialize the dataset by giving the dataset path and transform that will be applied \"\"\"\n",
    "    def __init__(self,transform = None):\n",
    "        images = []\n",
    "        wider_subjects = [subject for subject in os.listdir(wider_dataset)]\n",
    "        \n",
    "        \n",
    "        for subject in wider_subjects:\n",
    "            images.append(os.path.join(wider_dataset,subject))\n",
    "\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.count = len(images)\n",
    "        \n",
    "\n",
    "    \"\"\" Image with given index will be loaded by using the image path \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = load_image(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=False, upsample=False, nobn = False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        self.downsample = downsample\n",
    "        self.nobn = nobn\n",
    "        if self.upsample:\n",
    "            self.conv1 = nn.ConvTranspose2d(inplanes, planes, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        if not self.nobn:\n",
    "            self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        if self.downsample:\n",
    "            self.conv2 =nn.Sequential(nn.AvgPool2d(2,2), conv3x3(planes, planes))\n",
    "        else:\n",
    "            self.conv2 = conv3x3(planes, planes)\n",
    "        if not self.nobn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        if inplanes != planes or self.upsample or self.downsample:\n",
    "            if self.upsample:\n",
    "                self.skip = nn.ConvTranspose2d(inplanes, planes, 4, 2, 1)\n",
    "            elif self.downsample:\n",
    "                self.skip = nn.Sequential(nn.AvgPool2d(2,2), nn.Conv2d(inplanes, planes, 1, 1))\n",
    "            else:\n",
    "                self.skip = nn.Conv2d(inplanes, planes, 1, 1, 0)\n",
    "        else:\n",
    "            self.skip = None\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if not self.nobn:\n",
    "            out = self.bn1(x)\n",
    "            out = self.relu(out)\n",
    "        else:\n",
    "            out = self.relu(x)\n",
    "        out = self.conv1(out)\n",
    "        if not self.nobn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.skip is not None:\n",
    "            residual = self.skip(x)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "    # Upsamplings can be changed with pixelShuffle\n",
    "class HighToLowGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HighToLowGenerator, self).__init__()\n",
    "        self.layers_in = conv3x3(3, 64)\n",
    "        # 64x64\n",
    "        self.residual1 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,64,downsample=True))\n",
    "        # 32x32\n",
    "        self.residual2 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,64,downsample=True))\n",
    "        # 16x16\n",
    "        self.residual3 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,64,downsample=True))\n",
    "        # 8x8\n",
    "        self.residual4 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,64,downsample=True))\n",
    "        # 4x4\n",
    "        self.residual5 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,64,upsample=True))\n",
    "        # 8x8\n",
    "        self.residual6 = nn.Sequential(BasicBlock(64,64),BasicBlock(64,3,upsample=True),nn.Tanh())\n",
    "        # 16x16\n",
    "        \n",
    "        \n",
    "    def forward(self, input, noise= None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn([input.size()[0],3,64,64]).to(device)\n",
    "        \n",
    "        x = input + noise \n",
    "        x = self.layers_in(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.residual3(x)\n",
    "        x = self.residual4(x)\n",
    "        x = self.residual5(x)\n",
    "        out = self.residual6(x)\n",
    "        return out\n",
    "        \n",
    "class LowDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LowDiscriminator, self).__init__()\n",
    "\n",
    "\n",
    "        self.disc = nn.Sequential(BasicBlock(3,6,nobn=True),\n",
    "                                  BasicBlock(6,6,nobn=True),\n",
    "                                  BasicBlock(6,12,nobn=True),\n",
    "                                  BasicBlock(12,12,nobn=True),\n",
    "                                  BasicBlock(12,6,nobn=True),\n",
    "                                  BasicBlock(6,6,nobn=True))  \n",
    "        self.linear = nn.Sequential(nn.Linear(16*16*6, 1),\n",
    "                                    nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,input):\n",
    "        x = self.disc(input)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5006\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "high_dataset = HighDataset(transform)\n",
    "low_dataset = LowDataset(transform) \n",
    "high_loader = DataLoader(high_dataset,batch_size = hightolow_batch_size)\n",
    "low_loader = DataLoader(low_dataset,batch_size = hightolow_batch_size)\n",
    "print(len(high_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e5b33d919cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpred_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhightolow_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "start_time = time.time()\n",
    "GANLoss = nn.HingeEmbeddingLoss().to(device)\n",
    "L2Loss = nn.MSELoss().to(device)\n",
    "hightolow_generator = HighToLowGenerator().to(device)\n",
    "hightolow_discriminator = LowDiscriminator().to(device)\n",
    "optimizer_G = torch.optim.Adam(hightolow_generator.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))\n",
    "optimizer_D = torch.optim.Adam(hightolow_discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))\n",
    "fixed_noise = torch.randn([hightolow_batch_size,3,64,64]).float().to(device)\n",
    "\n",
    "def sample_images(batches_done):\n",
    "    it = iter(high_dataset)\n",
    "    nxt_batch = next(it)\n",
    "    nxt_batch = nxt_batch.to(device)\n",
    "    if hightolow_batch_size != nxt_batch.size()[0]:\n",
    "        fixed_noise = fixed_noise[nxt_batch.size()[0],:,:,:]\n",
    "    samples = hightolow_generator(nxt_batch, fixed_noise)\n",
    "    vutils.save_image(samples, \"Checkpoint/%s.png\" % batches_done, normalize=True )\n",
    "\n",
    "batches_done = 0  \n",
    "\n",
    "for cur_epoch in range(epoch):\n",
    "    for i, batch in enumerate(high_loader):\n",
    "        valid = torch.from_numpy(np.ones((batch.size()[0], 1))).float().to(device)\n",
    "        fake =  torch.from_numpy(np.zeros((batch.size()[0], 1))).float().to(device)\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        low_batch = next(low_it).to(device)\n",
    "        # Train discriminator with real\n",
    "        optimizer_D.zero_grad()\n",
    "        pred_real = hightolow_discriminator(low_batch)\n",
    "        loss_D = L2Loss(pred_real,valid)\n",
    "        loss_D.backward()\n",
    " \n",
    "        \n",
    "        # Train discriminator with fake\n",
    "\n",
    "        fake_batch = hightolow_generator(batch)\n",
    "        pred_fake = hightolow_discriminator(fake_batch)\n",
    "        loss_D = L2Loss(pred_fake,fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        batches_done += 1\n",
    "        # Train generator if ratio is reached\n",
    "        if i % generator_update_ratio == 0:\n",
    "            # Train it\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            fake_batch = hightolow_generator(batch)\n",
    "            loss_L2 = L2Loss(fake_batch,low_batch)\n",
    "            loss_G = GANLoss(hightolow_discriminator(fake_batch),valid)\n",
    "            total_loss = loss_a_coeff*loss_L2 + loss_b_coeff*loss_G\n",
    "            total_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Log the progress\n",
    "            # Calculate remaining time\n",
    "        if i% sample_interval\n",
    "            info = \"===> Epoch[{}]({}/{}): time: {:4.4f}:\".format(cur_epoch, i, len(high_loader), time.time()-start_time)\n",
    "            info += \"Generator: {:.4f}, Discriminator: {:.4f}\".format(total_loss, loss_D)     \n",
    "            print(info)\n",
    "            \n",
    "            # If at sample interval sample and save images\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(data_loader)\n",
    "batch = next(it)\n",
    "model = HighToLowGenerator(random_noise=True)\n",
    "out = model(batch)\n",
    "model2 = LowDiscriminator()\n",
    "predict = model2(out)\n",
    "print(predict)\n",
    "vutils.save_image(out,\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
